{
  "hash": "48b9ebfd515b34c2d9726070514c55cf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Embrace the darkness\"\nauthor: \n  - name: Gerko Vink\n    orcid: 0000-0001-9767-1924\n    email: g.vink@uu.nl\n    affiliations:\n      - name: Methodology & Statistics @ Utrecht University\ndate: 31 May 2024\ndate-format: \"D MMM YYYY\"\nexecute: \n  echo: true\nformat: \n  revealjs:\n    theme: [solarized, gerko.scss]\n    progress: true\n    margin: 0.075\n    logo: logo.png \n    toc: false\n    toc-depth: 1\n    toc-title: Outline\n    slide-number: true\n    scrollable: false\n    width: 1200\n    reference-location: margin\n    footer: Gerko Vink @ UU - based on slides by Stef van Buuren, Hanne Oberman and myself - 31 May 2024, Utrecht\n    standalone: true\n---\n\n\n## Disclaimer\n\nI owe a debt of gratitude to many people as the thoughts and code in these slides are the process of years-long development cycles and discussions with my team, friends, colleagues and peers. When someone has contributed to the content of the slides, I have credited their authorship.\n\nScientific references are in the footer. Opinions and figures are my own, AI-generated or directly linked.\n\n## Clichés out of the way!\n\n> Everything is a missing data problem \n\n> All models are wrong, but some are useful\n\n> How wrong can a model be to still be useful?\n\n## Topics for this lecture\n- Problem of dark data\n- Strategies to deal with missing data\n- Multiple imputation methodology to analyse incomplete data \n- Synthetic data sets for disclosure protection\n\n## What is dark data?\n::: .callout-note\nDark data are concealed from us, and that very fact means we are at risk of misunderstanding, of drawing incorrect conclusions, and of making poor decisions.\n:::\n\n------------------------------------------------------------------------\n\n<center>![](img/darkdata.jpg){height=\"680\"}</center>\n\n------------------------------------------------------------------------\n\n## Dark data types\n\n|  No | Description                    |  No | Description                       |\n|-----------------:|:-----------------|-----------------:|:-----------------|\n|   1 | Data We Know Are Missing       |   9 | Summaries of Data                 |\n|   2 | Data We Don't Know are Missing |  10 | Measurement Error and Uncertainty |\n|   3 | Choosing Just Some Cases       |  11 | Feedback and Gaming               |\n|   4 | Self-Selection                 |  12 | Information Asymmetry             |\n|   5 | Missing What Matters           |  13 | Intentionally Darkened Data       |\n|   6 | Data Which Might Have Been     |  14 | Fabricated and Synthetic Data     |\n|   7 | Changes with Time              |  15 | Extrapolating beyond Your Data    |\n|   8 | Definitions of Data            |  16 | Data not yet observable           |\n|     |                                |     |                                   |\n\n## **Concepts**: Definition\n\n-   Missing values are those values that are not observed\n-   Values do exist in theory, but we are unable to see them\n\n## **Concepts**: Reasons\n\nMissing or dark data can occur for a lot of reasons. Or for no reason at all. For example\n\n-   Intentional: Sample, predict, combine, estimate\n    -   routing\n    -   experimental design\n    -   join, merge and bind operations\n-   Unintentional:\n    -   dropout, refusal, concealed\n    -   too far away, too small to observe\n    -   power failure, budget exhausted, bad luck\n\n## **Consequences**: Why are missing values problematic?\n\n-   Cannot calculate, not even the mean\n-   Less information than planned\n-   Enough statistical power?\n-   Different analyses, different $n$'s\n-   Systematic biases in the analysis\n-   Appropriate confidence interval, $p$-values?\n\n. . .\n\nMissing data can severely complicate interpretation and analysis\n\n\n## **Notation**: $Y$, $R$, $X$\n\n:::: {layout=\"[ 40, 60 ]\"}\n\n::: {#first-column}\n\n![](figures/mdpattern.png){width=\"400\"}\n\n:::\n\n::: {#second-column}\n\n<br>\n\n-   $Y$ random variable with missing data\n-   $Y^\\mathrm{obs}$ true and observed values of $Y$\n-   $Y^\\mathrm{mis}$ true but unobserved values of $Y$\n\n<br>\n\n-   $X$ complete covariate\n\n<br>\n\n-   $R$ response indicator\n-   $R = 1$ if $Y$ is observed\n-   $R = 0$ if $Y$ is missing\n:::\n\n::::\n\n## Types of distributions\n\n-   **Marginal distribution** $P(Y)$\n    -   frequency distribution/histogram of $Y$\n    -   normal distribution with mean $\\mu$ and variance $\\sigma^2$\n-   **Joint distribution** $P(Y, X)$\n    -   contingency table/scatterplot of $Y$ and $X$\n    -   bivariate normal distribution\n-   **Conditional distribution** $P(Y | X)$\n    -   distribution of $Y$ at a given value of $X$\n    -   regression model with normally distributed errors\n\n<!-- # Two types of models {background-color=\"#2a76dd\"} -->\n\n## The complete-data model\n\n-   The model we would like to fit if we had complete data\n-   The model of scientific interest\n-   Examples:\n    -   $P(Y | X, \\theta)$: Predict blood pressure $Y$ from health $X$\n    -   $P(\\theta | Y)$: Estimate gross domestic product $\\theta$ from production $Y$\n\n## The missing data model (mechanism)\n\n-   The model that explains what is observed\n-   Often not of direct scientific interest\n-   Examples:\n    -   $P(R | Y, X, \\psi)$: Missingness depends on design covariates $X$\n    -   $P(R | Y, \\psi)$: Missingness depends on incomplete $Y$\n\n# Missing data mechanisms {background-color=\"#2a76dd\"}\n\n## Missing data mechanism: A key assumption\n\n-   We assume we know **where** the missing data are\n\n-   Cases where the assumption does not hold:\n\n    -   \"Tick any of the following\" (we don't know which values are real)\n    -   Truncated data (we don't know how many values are missing)\n\n## Missing data mechanism: Definition\n\n-   Process that governs which $Y$s are observed and which $Y$s are unobserved (Rubin, 1976)\n-   Sometimes we know this process (e.g.\\~experimental design, sampling)\n-   Model by response probability $P(R | Y^\\mathrm{obs}, Y^\\mathrm{mis}, X)$\n-   Also called **missing data model**\n\n## MCAR: Missing Completely at Random\n\n-   Probability to be missing is not related to any data\n\n. . . \n\n$$\nP(R|Y^\\mathrm{obs}, Y^\\mathrm{mis}, X, \\psi) = P(R|\\psi)\n$$\n\n-   Examples\n    -   data transmission error\n    -   random sample\n\nDavid Hand calls this mechanism **Not Data Dependent**\n\n## MAR: Missing at Random\n\n-   Probability to be missing depends on known data\n\n. . . \n\n$$\nP(R|Y^\\mathrm{obs}, Y^\\mathrm{mis}, X, \\psi) = P(R|Y^\\mathrm{obs}, X, \\psi)\n$$\n\n-   Examples\n    -   Income, where we have $X$ related to wealth\n    -   Branch patterns (e.g. how old are your children?)\n\nDavid Hand calls this mechanism **Seen Data Dependent**\n\n## MNAR: Missing Not at Random\n\n-   Probability to be missing depends on unknown data\n\n. . . \n\n$$\nP(R|Y^\\mathrm{obs}, Y^\\mathrm{mis}, X, \\psi)\n$$\n\ndoes not simplify\n\n-   Examples\n    -   Income, without covariates related to income\n    -   Body weight report\n\nDavid Hand calls this mechanism **Unseen Data Dependent**\n\n## Missing data mechanisms: roundup\n\n-   **Missing Completely at Random** (MCAR)\n    -   missingness is purely random\n    -   relatively easy to deal with\n-   **Missing at Random** (MAR)\n    -   missingness related to observed information\n    -   widely used for principled analysis\n-   **Missing Not at Random** (MNAR)\n    -   missingness related to unobserved information\n    -   cannot detect this from the data\n    -   difficult to deal with, need context information\n\n## Missing data mechanisms: Graphical representation\n\n![](figures/DAG.png)\n\n::: footer\nSchafer, J. L. & Graham, J. W. (2002). Missing Data. Psychological Methods, 7 (2), 147-177. [doi: 10.1037/1082-989X.7.2.147](https://pubmed.ncbi.nlm.nih.gov/12090408/)\n:::\n\n## Missing data mechanisms: Alternative terminology\n\n- Not Data Dependent (~MCAR)\n  - It’s missing for reasons unrelated to the data\n  - Probability to be missing is constant for all units\n  - E.g. some students not sitting an exam due to flu symptoms\n- Seen Data Dependent (~MAR)\n  - It’s missing for reasons related to data you have got\n  - Probability to be missing depends on *observed* data \n  - E.g. school discouraging lower performing students from sitting exam\n- Unseen Data Dependent (~MNAR)\n  - Missing because of the values you would have obtained\n  - Probability to be missing depends on *unobserved* data \n  - E.g. students realized revised wrong material, so didn’t sit exam\n\n<!-- https://infomdwr.nl/lectures/week_7/1_missing_data_1.pdf -->\n\n\n## Uwe Aickelin: What to do with the missing data?\n\n<https://www.youtube.com/watch?v=oCQbC818KKU>\n\n## Lessons from Uwe Aickelin\n\n-   You could obtain the data, but it's not there\n-   Quality of data is going down - big data\n-   Why not go back to expert? Impractical\n-   Why not delete? What to delete?\n-   Reasons for missing data are important\n-   Missing (Completely?) at Random\n-   How impute? Mean, random, mean per group\n-   Software cannot handle missing data\n-   Forced internet surveys\n\n\n# Strategies to deal with missing data {background-color=\"#2a76dd\"}\n\n## Strategies\n\n1.  Prevention\n2.  Ad-hoc methods, e.g., single imputation, complete cases\n3.  Weighting methods\n4.  Likelihood methods, EM-algorithm\n5.  Multiple imputation\n\n## Strategies\n\n::: {.nonincremental}\n1.  **Prevention**\n2.  Ad-hoc methods, e.g., single imputation, complete cases\n3.  Weighting methods\n4.  Likelihood methods, EM-algorithm\n5.  Multiple imputation\n:::\n\n##  {background-color=\"#2a76dd\"}\n\n::: {style=\"margin-top: 40px; font-size: 3.5em;\"}\n**Prevent unintended missing data**\n:::\n\n## 1. Prevention strategies\n\n-   Design: Time intervals, Number of variables, Pilot study\n-   Collection: Incentives, Match interviewer-respondent, Quick follow-up, Retrieve missing data\n-   Measures: Use short forms, Minimize intrusive measures, Clarity, Layout\n-   Treatment: Minimize burden and intensity\n\n## Strategies\n\n::: {.nonincremental}\n1.  Prevention\n2.  **Ad-hoc methods, e.g., single imputation, complete cases**\n3.  Weighting methods\n4.  Likelihood methods, EM-algorithm\n5.  Multiple imputation\n:::\n\n##  {background-color=\"#2a76dd\"}\n\n::: {style=\"margin-top: 40px; font-size: 3.5em;\"}\n**Ad-hoc methods make strong assumptions**\n:::\n\n## 2. Ad-hoc strategies\n\n-   Listwise deletion\n-   Mean imputation\n-   Regression imputation\n-   Stochastic regression imputation\n-   Last observation carried forward (LOCF)\n-   Indicator method\n\n## Listwise deletion\n\n-   Analyze only the complete records\n-   Also know as: complete-case analysis\n-   Advantages\n    -   Simple (default in most software)\n    -   Unbiased under MCAR\n    -   Conservative standard errors, significance levels\n    -   Two special properties in regression\n\n## Listwise deletion\n\n-   Disadvantages\n    -   Wasteful\n    -   May not be possible\n    -   Larger standard errors\n    -   Biased under MAR, even for simple statistics like the mean\n    -   Inconsistencies in reporting\n\n## Listwise deletion: Special properties\n\n-   For any regression with missing data in the predictors, estimates under listwise deletion are unbiased as long as the missingness does not depend on the outcome. Even some MNAR cases (Glynn 1986; Little 1992).\n-   In logistic regression only: With missing data in either the outcome $Y$ or the predictors $X$ (but not both), estimates of regression weights (but not the intercept) after listwise deletion are unbiased as long as the missingness depends only on $Y$ (and not on $X$!) (Vach 1994). This property is widely exploited in case-control studies in epidemiology.\n-   See FIMD 2.7: <https://stefvanbuuren.name/fimd/sec-when.html>\n\n## Mean imputation\n\n-   Replace the missing values by the mean of the observed data\n-   Advantages\n    -   Simple\n    -   Unbiased for the mean, under MCAR\n\n## Mean imputation\n\n\n::: {.cell duo='true'}\n::: {.cell-output-display}\n![](dark_files/figure-revealjs/unnamed-chunk-1-1.png){width=864}\n:::\n:::\n\n\n## Mean imputation\n\n-   Disadvantages\n    -   Disturbs the distribution\n    -   Underestimates the variance\n    -   Biases correlations to zero\n    -   Biased under MAR\n-   AVOID (unless you know what you are doing)\n\n## Regression imputation\n\n-   Also known as **prediction**\n    -   Fit model for $Y^\\mathrm{obs}$ under listwise deletion\n    -   Predict $Y^\\mathrm{mis}$ for records with missing $Y$s\n    -   Replace missing values by prediction\n-   Advantages\n    -   Under MAR, unbiased estimates of regression coefficients\n    -   Good approximation to the (unknown) true data if explained variance is high\n-   Favourite among data scientists and machine learners\n\n## Regression imputation\n\n\n::: {.cell duo='true'}\n::: {.cell-output-display}\n![](dark_files/figure-revealjs/unnamed-chunk-2-1.png){width=864}\n:::\n:::\n\n\n## Regression imputation\n\n-   Disadvantages\n    -   Artificially increases correlations\n    -   Systematically underestimates the variance\n    -   Too optimistic $p$-values and too short confidence intervals\n-   AVOID. Harmful to statistical inference\n\n## Stochastic regression imputation\n\n-   Like regression imputation, but adds appropriate noise to the predictions to reflect uncertainty\n-   Advantages\n    -   Preserves the distribution of $Y^\\mathrm{obs}$\n    -   Preserves the correlation between $Y$ and $X$ in the imputed data\n\n## Stochastic regression imputation\n\n\n::: {.cell duo='true'}\n::: {.cell-output-display}\n![](dark_files/figure-revealjs/unnamed-chunk-3-1.png){width=864}\n:::\n:::\n\n\n## Stochastic regression imputation\n\n-   Disadvantages\n    -   Symmetric and constant error restrictive\n    -   Single imputation: does not take uncertainty imputed data into account, and incorrectly treats them as real\n    -   Not so simple anymore\n\n## Overview of assumptions needed\n\n|            |      |            |             |                |\n|------------|------|:----------:|-------------|----------------|\n|            |      |  Unbiased  |             | Standard Error |\n|            | Mean | Reg Weight | Correlation |                |\n| Listwise   | MCAR |    MCAR    | MCAR        | Too large      |\n| Pairwise   | MCAR |    MCAR    | MCAR        | Complicated    |\n| Mean       | MCAR |     --     | --          | Too small      |\n| Regression | MAR  |    MAR     | --          | Too small      |\n| Stochastic | MAR  |    MAR     | MAR         | Too small      |\n| LOCF       | --   |     --     | --          | Too small      |\n| Indicator  | --   |     --     | --          | Too small      |\n\n## Strategies\n\n::: {.nonincremental}\n1.  Prevention\n2.  Ad-hoc methods, e.g., single imputation, complete cases\n3.  **Weighting methods**\n4.  Likelihood methods, EM-algorithm\n5.  Multiple imputation\n:::\n\n##  {background-color=\"#2a76dd\"}\n\n::: {style=\"margin-top: 40px; font-size: 3.5em;\"}\n**Weighting minimizes bias with unit nonresponse**\n:::\n\n## 3. Weighting\n\n-   Take the complete cases\n-   Re-weight any statistic to the distribution of the covariates in the population\n-   Advantages\n    -   Simple (one set of weights for all incomplete variables)\n    -   Reduces bias under MAR assumption\n    -   Standard methodology in official statistics\n-   Disadvantages\n    -   Discards data, increases the variance\n    -   Weights may not be available\n    -   Needs special variance estimators\n    -   Limited to unit non-response\n\nFor inferences purposes, proper imputation strategies prove to quickle become more efficient and more accurate than weighting strategies (Boeschoten et al., 2017).\n\n::: footer\nBoeschoten, L., Vink, G., & Hox, J. J. C. M. (2017). How to Obtain Valid Inference under Unit Nonresponse? Journal of Official Statistics, 33(4), 963-978. [https://doi.org/10.1515/jos-2017-0045](https://doi.org/10.1515/jos-2017-0045)\n:::\n\n## Strategies\n\n::: {.nonincremental}\n1.  Prevention\n2.  Ad-hoc methods, e.g., single imputation, complete cases\n3.  Weighting methods\n4.  **Likelihood methods, EM-algorithm**\n5.  Multiple imputation\n:::\n\n##  {background-color=\"#2a76dd\"}\n\n::: {style=\"margin-top: 40px; font-size: 3.5em;\"}\n**Maximum likelihood: The royal road to missing data**\n:::\n\n## 4. Maximum likelihood\n\n-   EM-algorithm, Full Information Maximum Likelihood (FIML)\n-   Iterative methods to estimate parameters that \"skip over\" the missing data\n-   Advantages:\n    -   Theoretically sound, optimizes likelihood calculation directly\n    -   Many applications, widely accepted\n    -   Easy to apply (when there is software)\n-   Disadvantages:\n    -   Local minima, slow convergence\n    -   Difficult to apply outside standard models\n    -   Complete-data model becomes large and complex\n\n<!-- ## Maximum likelihood software -->\n\n<!-- -   Mixed models: Proc Mixed (SAS), MLWin -->\n<!-- -   Structural models: AMOS, Mplus, Mx -->\n<!-- -   Rasch analyse: RUMM2030 -->\n\n## Strategies\n\n::: {.nonincremental}\n1.  Prevention\n2.  Ad-hoc methods, e.g., single imputation, complete cases\n3.  Weighting methods\n4.  Likelihood methods, EM-algorithm\n5.  **Multiple imputation**\n:::\n\n##  {background-color=\"#2a76dd\"}\n\n::: {style=\"margin-top: 40px; font-size: 3.5em;\"}\n**Multiple imputation is an all-round principled method**\n:::\n\n## 5. Multiple imputation\n\n-   One imputation cannot be correct in general\n-   Imputes each missing value $m$ times\n-   Variation between the $m$ imputed values reflects our ignorance about the unknown value\n\n## Multiple imputation workflow\n\n<center>![](figures/ch01-miflow-1.png){height=\"600\"}</center>\n\n## Multiple imputation - 1987\n\n::: {layout-ncol=\"2\" layout-valign=\"bottom\"}\n![](figures/rubin1987_cover.jpeg){width=\"400\"}\n\n![](figures/Donald-Rubin-HS-768x768.jpg){width=\"500\"}\n:::\n\n## Multiple imputation\n\n-   Advantages\n    -   Correct point and variance estimates\n    -   Splits missing data problem from complete-data analysis\n    -   Theoretical properties well established\n    -   Flexible, widely applicable\n    -   Extensible to MNAR\n-   Disadvantages\n    -   Need to create and work with multiple imputed data sets\n    -   May not always be most efficient\n\n## What is the goal of multiple imputation?\n\nThe goal:\n\n- **IS NOT** to find the correct value for a missing data point\n- **IS** to find an answer to the analysis problem, given that there are (many) data points missing.\n\nWe are not interested in whether the imputed value corresponds to its true counterpart in the population, but we rather sample plausible values that could have been from the posterior predictive distribution\n\n## Demonstration of imputation\nLet our analysis model be\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nboys %$% # use the exposition pipe\n  lm(hgt ~ age + tv)\n```\n:::\n\n\n## Demonstration of imputation\nwith output\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboys %$% \n  lm(hgt ~ age + tv) %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = hgt ~ age + tv)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-24.679  -5.134  -0.398   5.175  23.778 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 105.4823     3.4704  30.395  < 2e-16 ***\nage           3.8430     0.3262  11.782  < 2e-16 ***\ntv            0.4919     0.1278   3.849 0.000155 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.389 on 221 degrees of freedom\n  (524 observations deleted due to missingness)\nMultiple R-squared:  0.7742,\tAdjusted R-squared:  0.7721 \nF-statistic: 378.8 on 2 and 221 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n## Demonstration of imputation\ngenerated on 224 cases. The full data size is\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboys %>% dim()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 748   9\n```\n\n\n:::\n:::\n\n\n\n## Demonstration of imputation\nTo impute and analyze the same model with `mice`, we can simply run:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboys %>% \n  mice(m = 5, method = \"cart\", printFlag = FALSE) %>% \n  complete(\"all\") %>% \n  map(~.x %$% lm(hgt ~ age + tv)) %>% \n  pool() %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         term   estimate  std.error  statistic       df      p.value\n1 (Intercept) 71.5467019 0.61617119 116.114975 735.4492 0.000000e+00\n2         age  7.0475726 0.09475359  74.377898  75.9456 1.043045e-72\n3          tv -0.5577935 0.09163996  -6.086793  39.9114 3.598196e-07\n```\n\n\n:::\n:::\n\n<center>\n![](img/imp_process.png){width=\"60%\"}\n</center>\n\n## What have we done?\nWe have used `mice` to obtain draws from a posterior predictive distribution of the missing data, conditional on the observed data. \n\nThe imputed values are mimicking the sampling variation and can be used to infer about the underlying TDGM, **if and only if**:\n\n- The observed data holds the information about the missing data (MAR/MCAR)\n\n# Synthetic data generation\n\n## Imputation vs Synthetisation\nInstead of drawing only imputations from the posterior predictive distribution, we might as well overimpute the observed data. \n![](img/patterns.png)\n\n## How to draw synthetic data sets with `mice`\n\n::: {.cell}\n\n```{.r .cell-code}\nboys %>% \n  mice(m = 5, method = \"cart\", printFlag = FALSE, where = matrix(TRUE, 748, 9)) %>% \n  complete(\"all\") %>% \n  map(~.x %$% lm(hgt ~ age + tv)) %>% \n  pool() %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         term   estimate std.error statistic       df      p.value\n1 (Intercept) 71.4727297 0.7637067 93.586620 71.79955 8.889816e-77\n2         age  6.8882608 0.1210342 56.911699 21.81539 3.232474e-25\n3          tv -0.4038602 0.1028084 -3.928281 33.89849 3.989687e-04\n```\n\n\n:::\n:::\n\n<center>\n![](img/synth_process.png){width=\"60%\"}\n</center>\nBut we make an error!\n\n## Pooling in imputation\nRubin (1987, p76) defined the following rules:\n\nFor any number of multiple imputations $m$, the combination of the analysis results for any estimate $\\hat{Q}$ of estimand $Q$ with corresponding variance $U$, can be done in terms of the average of the $m$ complete-data estimates\n\n$$\\bar{Q} = \\sum_{l=1}^{m}\\hat{Q}_l / m,$$\n\nand the corresponding average of the $m$ complete data variances\n\n$$\\bar{U} = \\sum_{l=1}^{m}{U}_l / m.$$ \n\n::: footer\nRubin, D.B. (1987). Multiple Imputation for Nonresponse in Surveys. New York: John Wiley and Sons.\n:::\n\n## Pooling in imputation\nSimply using $\\bar{Q}$ and $\\bar{U}_m$ to obtain our inferences would be to simplistic. In that case we would ignore any possible variation between the separate $\\hat{Q}_l$ and the fact that we only generate a finite set of imputations $m$. Rubin (1987, p. 76) established that the total variance $T$ of $(Q-\\bar{Q})$ would equal\n\n$$T = \\bar{U} + B + B/m,$$\n\nWhere the between imputation variance $B$ is defined as \n\n$$B = \\sum_{l=1}^{m}(\\hat{Q}_l - \\bar{Q})^\\prime(\\hat{Q}_l - \\bar{Q}) / (m-1)$$\n\n**This assumes that some of the data are observed and remain constant over the synthetic sets**\n\nThe total variance $T$ of $(Q-\\bar{Q})$ should (Reiter, 2003) equal\n\n$$T = \\bar{U} + B/m.$$\n\n::: footer\nReiter, J.P. (2003). Inference for Partially Synthetic, Public Use Microdata Sets. Survey Methodology, 29, 181-189.\n:::\n\n## So, the correct code is \n\n::: {.cell}\n\n```{.r .cell-code}\nboys %>% \n  mice(m = 5, method = \"cart\", printFlag = FALSE, where = matrix(TRUE, 748, 9)) %>% \n  complete(\"all\") %>% \n  map(~.x %$% lm(hgt ~ age + tv)) %>% \n  pool(rule = \"reiter2003\") %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         term   estimate  std.error  statistic         df       p.value\n1 (Intercept) 71.3427191 0.67872263 105.113218 4670.20788  0.000000e+00\n2         age  6.9161820 0.09961066  69.432144  178.28359 5.318364e-131\n3          tv -0.4015052 0.09691269  -4.142958   56.62364  1.155999e-04\n```\n\n\n:::\n:::\n\n\n## Why multiple synthetic sets?\nThank back about the goal of statistical inference: we want to go back to the true data generating model.\n\n1. We do so by reverse engineering the true data generating process\n2. Based on our observed data\n3. We do not know this process; hence multiple synthetic values\n\nThe multiplicity of the solution allows for smoothing over any Monte Carlo error that may arise from generating a single set.\n\n## Generating more synthetic data\n\n::: {.cell}\n\n```{.r .cell-code}\nmira <- boys %>% \n  mice(m = 6, method = \"cart\", printFlag = FALSE, where = matrix(TRUE, 748, 9)) %>% \n  list('1' = rbind(complete(., 1), complete(., 2)),\n       '2' = rbind(complete(., 3), complete(., 4)),\n       '3' = rbind(complete(., 5), complete(., 6))) %>% .[-1] %>% \n  data.table::setattr(\"class\", c(\"mild\", class(.))) %>% \n  map(~.x %$% lm(hgt ~ reg))\n\nmira %>% pool(rule = \"reiter2003\") %>% \n  summary() %>% tibble::column_to_rownames(\"term\") %>% round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            estimate std.error statistic      df p.value\n(Intercept)  152.014     3.746    40.582 112.526       0\nregeast      -17.815     4.461    -3.993 771.076       0\nregwest      -23.092     4.397    -5.252  95.353       0\nregsouth     -27.579     4.451    -6.196 177.098       0\nregcity      -25.928     6.111    -4.243  19.899       0\n```\n\n\n:::\n\n```{.r .cell-code}\nmira %>% pool(rule = \"reiter2003\", \n              custom.t = \".data$ubar * 2 + .data$b / .data$m\") %>% \n  summary() %>% tibble::column_to_rownames(\"term\") %>% round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            estimate std.error statistic      df p.value\n(Intercept)  152.014     5.118    29.703 112.526   0.000\nregeast      -17.815     6.228    -2.860 771.076   0.004\nregwest      -23.092     5.989    -3.856  95.353   0.000\nregsouth     -27.579     6.125    -4.503 177.098   0.000\nregcity      -25.928     7.928    -3.270  19.899   0.004\n```\n\n\n:::\n:::\n\nSome adjustment to the pooling rules is neede to avoid p-inflation.\n\n::: footer\nRaab, Gillian M, Beata Nowok, and Chris Dibben. 2018. “Practical Data Synthesis for Large Samples”. Journal of Privacy and Confidentiality 7 (3):67-97. [https://doi.org/10.29012/jpc.v7i3.407.](https://doi.org/10.29012/jpc.v7i3.407)\n:::\n\n## Some care is needed\nWith synthetic data generation and synthetic data implementation come some risks. \n\nAny idea?\n\n# What should synthetic data be?\n\n## Testing validity\nNowadays many synthetic data cowboys claim that they can generate synthetic data that looks like the real data that served as input. \n\nThis is like going to Madam Tusseaud's: at face value it looks identical, but when experienced in real life it's just not the same as the living thing. \n\nMany of these synthetic data packages only focus on marginal or conditional distributions. With `mice` we also consider the inferential properties of the synthetic data. \n\nIn general, we argue [^4] that any synthetic data generation procedure should\n\n1. Preserve marginal distributions\n2. Preserve conditional distribution\n3. Yield valid inference\n4. Yield synthetic data that are indistinguishable from the real data\n\n\n::: footer\nVolker, T.B.; Vink, G. Anonymiced Shareable Data: Using mice to Create and Analyze Multiply Imputed Synthetic Datasets. Psych 2021, 3, 703-716. [https://doi.org/10.3390/psych3040045](https://doi.org/10.3390/psych3040045)\n:::\n\n## Example from simulation\nWhen valid synthetic data are generated, the variance of the estimates is correct, such that the confidence intervals cover the population (i.e. true) value sufficiently [^5]. Take e.g. the following proportional odds model from Volker & Vink (2021):\n\n|        term | estimate | synthetic <br> bias   | synthetic <br> cov   |\n|-------------|---------:|-------:|------:|\n| age         | 0.461    | 0.002  | 0.939 |\n| hc          | -0.188   | -0.004 | 0.945 |\n| regeast     | -0.339   | 0.092  | 0.957 |\n| regwest     | 0.486    | -0.122 | 0.944 |\n| regsouth    | 0.646    | -0.152 | 0.943 |\n| regcity     | -0.069   | 0.001  | 0.972 |\n| G1$|$G2     | -6.322   | -0.254 | 0.946 |\n| G2$|$G3     | -4.501   | -0.246 | 0.945 |\n| G3$|$G4     | -3.842   | -0.244 | 0.948 |\n| G4$|$G5     | -2.639   | -0.253 | 0.947 |\n \n::: footer\nVolker, T.B.; Vink, G. Anonymiced Shareable Data: Using mice to Create and Analyze Multiply Imputed Synthetic Datasets. Psych 2021, 3, 703-716. [https://doi.org/10.3390/psych3040045](https://doi.org/10.3390/psych3040045)\n:::\n\n## End of presentation\n\n<center>\n![A. Bacall](https://imgc.allpostersimages.com/img/posters/scientist-sits-at-computer-that-has-a-thought-balloon-over-it-that-reads-cartoon_u-L-PGPH660.jpg?artHeight=900&artPerspective=n&artWidth=900){width=\"60%\"}\n</center>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}